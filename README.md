# ğŸš€ YOLOv10 Person Detection Training on Apple Silicon

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.2.2-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![YOLOv10](https://img.shields.io/badge/YOLOv10-Ultralytics-00FFFF.svg)](https://docs.ultralytics.com/)

> A production-ready YOLOv10 training pipeline optimized for **Apple Silicon (M4)** using the COCO "person" subset. Features environment-based configuration, professional project structure, and comprehensive documentation.

## âœ¨ Key Highlights

- ğŸ¯ **Specialized Training**: Focused person detection using 64,115 COCO images
- ğŸ **Apple Silicon Optimized**: Native MPS (Metal Performance Shaders) support for M1/M2/M3/M4 chips
- âš™ï¸ **Environment-Based Config**: Clean `.env` configuration system for easy deployment
- ğŸ“Š **COCO Pipeline**: Automated dataset download, filtering, and YOLO format conversion
- ğŸ”„ **Production Ready**: Professional project structure with MIT license and contribution guidelines
- ğŸ“ˆ **Performance Metrics**: ~0.58 batch/s on M4 with 19.4GB GPU utilization

## ğŸ“Š Performance Benchmarks

| Device | Model | Batch Size | Speed | GPU Memory | Time/Epoch |
|--------|-------|------------|-------|------------|------------|
| M4 (24GB) | YOLOv10s | 24 | 0.58 batch/s | 19.4GB | ~77 min |
| M4 (24GB) | YOLOv10n | 32 | 0.72 batch/s | 15.2GB | ~62 min |

**Estimated Training Time**: ~5.3 days for 100 epochs (YOLOv10s on M4)

## ğŸ¯ What's Inside

### Core Features

```
âœ… COCO Dataset Integration    â†’ Automated download and preprocessing
âœ… Person Class Filtering       â†’ 64,115 train + 2,693 validation images
âœ… YOLO Format Conversion       â†’ Normalized bounding box annotations
âœ… Apple MPS Backend           â†’ Native GPU acceleration for M-series chips
âœ… Environment Configuration   â†’ Flexible .env-based settings
âœ… Training Pipeline           â†’ Complete YOLOv10 training workflow
âœ… Inference Scripts           â†’ Image, video, and webcam support
```

### Project Architecture

```
yolo-person/
â”œâ”€â”€ ğŸ“„ .env.example            # Configuration template
â”œâ”€â”€ ğŸ“„ config.py               # Configuration loader with validation
â”œâ”€â”€ ğŸ“„ dataset.yaml            # YOLO dataset specification
â”œâ”€â”€ ğŸ“„ download_coco.py        # COCO 2017 downloader
â”œâ”€â”€ ğŸ“„ prepare_dataset.py      # COCOâ†’YOLO converter (person filter)
â”œâ”€â”€ ğŸ“„ train.py                # Main training script
â”œâ”€â”€ ğŸ“„ inference.py            # Inference runner
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“„ LICENSE                 # MIT License
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md         # Contribution guidelines
â”‚
â”œâ”€â”€ ğŸ“ data/                   # Raw COCO dataset (gitignored)
â”‚   â””â”€â”€ coco/
â”‚       â”œâ”€â”€ train2017/
â”‚       â”œâ”€â”€ val2017/
â”‚       â””â”€â”€ annotations/
â”‚
â”œâ”€â”€ ğŸ“ datasets/               # Processed YOLO format (gitignored)
â”‚   â””â”€â”€ coco_person/
â”‚       â”œâ”€â”€ images/
â”‚       â””â”€â”€ labels/
â”‚
â”œâ”€â”€ ğŸ“ runs/                   # Training outputs (gitignored)
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ detect/
â”‚
â””â”€â”€ ğŸ“ samples/                # Demo outputs (kept in git)
    â””â”€â”€ .gitkeep
```

## ğŸš€ Quick Start

### âš¡ Automated Setup (Recommended)

**New to this project? Run the automated setup script:**

```bash
git clone https://github.com/yourusername/yolo-person.git
cd yolo-person
./first-run.sh
```

The script will automatically:
- âœ… Check system requirements
- âœ… Create `.env` configuration with optimal settings
- âœ… Set up Python virtual environment
- âœ… Install all dependencies
- âœ… Run system tests

---

### ğŸ”§ Manual Setup

If you prefer manual setup:

### Prerequisites

- **Python**: 3.9 or higher
- **RAM**: 16GB minimum, 24GB+ recommended
- **Storage**: 150GB for full COCO dataset + processed data
- **GPU**: Apple Silicon (M1/M2/M3/M4) or NVIDIA CUDA

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/yolo-person.git
cd yolo-person
```

2. **Create virtual environment**

```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# or
venv\Scripts\activate     # Windows
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Configure environment**

```bash
cp .env.example .env
# Edit .env with your preferred settings
```

### Configuration

The project uses `.env` for all configurable parameters. Key settings:

```bash
# Model Configuration
MODEL_SIZE=s                    # n, s, m, l, x (nano to xlarge)
TRAINING_EPOCHS=100
BATCH_SIZE=24                   # Adjust based on GPU memory
IMAGE_SIZE=640

# Device Settings
DEVICE=mps                      # mps, cuda, cpu, or device ID
WORKERS=0                       # Set to 0 for MPS compatibility
AMP_ENABLED=false               # Mixed precision (disable for MPS stability)

# Paths
DATASET_PATH=./datasets/coco_person
COCO_PATH=./data/coco
PROJECT_PATH=./runs/train
```

See `.env.example` for full configuration options with detailed comments.

## ğŸ“– Usage Guide

### Step 1: Download COCO Dataset

Download COCO 2017 train/val splits (~19GB):

```bash
python download_coco.py
```

**Options:**
```bash
python download_coco.py --no-images      # Skip images (annotations only)
python download_coco.py --data-dir ./my_data
```

### Step 2: Prepare Person Dataset

Filter and convert COCO to YOLO format:

```bash
python prepare_dataset.py
```

**Output:**
- 64,115 training images with person annotations
- 2,693 validation images
- Normalized YOLO format: `<class> <x_center> <y_center> <width> <height>`

**Options:**
```bash
python prepare_dataset.py --coco-dir ./data/coco --output-dir ./datasets/custom
```

### Step 3: Train YOLOv10

Start training with your configured settings:

```bash
python train.py
```

**Training progress:**
```
Epoch   GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
1/100     19.4G      1.234      0.856      1.123        128        640
2/100     19.4G      1.156      0.782      1.067        128        640
...
```

**Outputs:**
```
runs/train/yolov10_person/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt          # Best model (highest mAP)
â”‚   â””â”€â”€ last.pt          # Last epoch checkpoint
â”œâ”€â”€ results.png          # Training curves
â”œâ”€â”€ confusion_matrix.png
â”œâ”€â”€ PR_curve.png
â””â”€â”€ F1_curve.png
```

### Step 4: Run Inference

Use your trained model for predictions:

```bash
# Webcam
python inference.py --source 0

# Image
python inference.py --source path/to/image.jpg

# Video
python inference.py --source path/to/video.mp4

# Directory
python inference.py --source path/to/images/

# Custom model + visualize
python inference.py --model runs/train/yolov10_person/weights/best.pt --source test.jpg --show
```

## ğŸ”§ Advanced Configuration

### Model Size Selection

| Model | Parameters | Speed | mAP | Use Case |
|-------|------------|-------|-----|----------|
| YOLOv10n | 2.3M | âš¡âš¡âš¡ | ğŸ¯ğŸ¯ | Mobile, edge devices |
| YOLOv10s | 7.2M | âš¡âš¡ | ğŸ¯ğŸ¯ğŸ¯ | **Balanced (recommended)** |
| YOLOv10m | 15.4M | âš¡ | ğŸ¯ğŸ¯ğŸ¯ğŸ¯ | High accuracy applications |
| YOLOv10l | 24.4M | ğŸŒ | ğŸ¯ğŸ¯ğŸ¯ğŸ¯ | Research, benchmarking |
| YOLOv10x | 29.5M | ğŸŒğŸŒ | ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ | Maximum accuracy |

Edit `.env`:
```bash
MODEL_SIZE=m  # Change to your preferred size
```

### Apple Silicon Optimization

**Key settings for M-series chips:**

```bash
DEVICE=mps                 # Use Metal Performance Shaders
WORKERS=0                  # Disable multiprocessing (MPS limitation)
AMP_ENABLED=false          # Disable mixed precision (stability)
CACHE_ENABLED=true         # Cache validation set in memory
BATCH_SIZE=24              # Optimal for M4 24GB (adjust for your RAM)
```

**Memory considerations:**
- M1 8GB: `BATCH_SIZE=8`
- M2 16GB: `BATCH_SIZE=16`
- M3/M4 24GB: `BATCH_SIZE=24-32`
- M3 Max 36GB+: `BATCH_SIZE=48+`

### Training Hyperparameters

All tunable via `.env`:

```bash
# Optimization
OPTIMIZER=AdamW             # AdamW, Adam, SGD
LEARNING_RATE=0.001
MOMENTUM=0.937
WEIGHT_DECAY=0.0005

# Regularization
DROPOUT=0.0
LABEL_SMOOTHING=0.0

# Augmentation
HSV_H=0.015                 # Hue augmentation
HSV_S=0.7                   # Saturation
HSV_V=0.4                   # Value
DEGREES=0.0                 # Rotation
TRANSLATE=0.1               # Translation
SCALE=0.5                   # Scale
SHEAR=0.0                   # Shear
FLIPUD=0.0                  # Flip up-down
FLIPLR=0.5                  # Flip left-right
MOSAIC=1.0                  # Mosaic augmentation

# Training
PATIENCE=50                 # Early stopping patience
CLOSE_MOSAIC=10            # Disable mosaic in last N epochs
```

## ğŸ“ˆ Monitoring Training

### Real-time Metrics

Monitor these key metrics during training:

- **Box Loss**: Bounding box regression quality
- **Class Loss**: Classification accuracy
- **DFL Loss**: Distribution focal loss (YOLOv10 specific)
- **mAP50**: Mean average precision at 0.5 IoU
- **mAP50-95**: mAP across IoU thresholds 0.5-0.95
- **Precision**: True positives / (True positives + False positives)
- **Recall**: True positives / (True positives + False negatives)

### Visualizations

Check generated plots in `runs/train/yolov10_person/`:

```
results.png              â†’ Training/validation metrics over time
confusion_matrix.png     â†’ Classification performance
PR_curve.png            â†’ Precision-Recall curve
F1_curve.png            â†’ F1 score vs confidence threshold
val_batch0_labels.jpg   â†’ Ground truth annotations
val_batch0_pred.jpg     â†’ Model predictions
```

## ğŸ› ï¸ Troubleshooting

### Common Issues

**Issue: Out of memory error**
```bash
# Solution: Reduce batch size in .env
BATCH_SIZE=16  # or lower
```

**Issue: Slow training on Mac**
```bash
# Solution: Verify MPS is active
python -c "import torch; print(torch.backends.mps.is_available())"  # Should be True

# Check .env settings
DEVICE=mps
WORKERS=0
AMP_ENABLED=false
```

**Issue: Dataset not found**
```bash
# Solution: Check paths in .env and dataset.yaml
DATASET_PATH=./datasets/coco_person  # Must match dataset.yaml
```

**Issue: Multiprocessing errors on Mac**
```bash
# Solution: Force workers to 0 in .env
WORKERS=0
```

### Performance Tuning

**Faster training (lower accuracy):**
```bash
MODEL_SIZE=n
BATCH_SIZE=32
IMAGE_SIZE=512
CLOSE_MOSAIC=0
```

**Higher accuracy (slower):**
```bash
MODEL_SIZE=l
BATCH_SIZE=16
IMAGE_SIZE=640
TRAINING_EPOCHS=200
MOSAIC=1.0
```

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Quick contribution workflow:**

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

**Third-party licenses:**
- COCO Dataset: [COCO Terms of Use](https://cocodataset.org/#termsofuse)
- YOLOv10/Ultralytics: [AGPL-3.0](https://github.com/ultralytics/ultralytics/blob/main/LICENSE)

## ğŸ“ Citation

If you use this project in your research, please cite:

```bibtex
@software{yolov10_person_2024,
  author = {Your Name},
  title = {YOLOv10 Person Detection Training on Apple Silicon},
  year = {2024},
  url = {https://github.com/yourusername/yolo-person}
}
```

## ğŸ“š Resources

- [Ultralytics YOLOv10 Documentation](https://docs.ultralytics.com/)
- [COCO Dataset Official Site](https://cocodataset.org/)
- [PyTorch MPS Backend Guide](https://pytorch.org/docs/stable/notes/mps.html)
- [Apple Silicon ML Performance](https://developer.apple.com/metal/)

## ğŸ™ Acknowledgments

- **Ultralytics** for the YOLOv10 implementation
- **COCO Consortium** for the comprehensive dataset
- **PyTorch Team** for MPS backend support
- **Apple** for Metal Performance Shaders optimization

## ğŸ“ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/yolo-person/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/yolo-person/discussions)
- **LinkedIn**: [Your Profile](https://linkedin.com/in/yourprofile)

---

**Made with â¤ï¸ for the Computer Vision Community**

*Star â­ this repo if you find it useful!*
